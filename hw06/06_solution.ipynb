{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a570f920",
   "metadata": {},
   "source": [
    "# Homework assignment №6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9924a33",
   "metadata": {},
   "source": [
    "# Music Generation (with xLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a97f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# conda env create --name xlstm -f environment_pt260cu126.yaml\n",
    "# conda activate xlstm\n",
    "# pip install xlstm mido midi2audio\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "from xlstm import xLSTMLMModel, xLSTMLMModelConfig\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "match device.type:\n",
    "    case \"cuda\":\n",
    "        print(f\"Device: {torch.cuda.get_device_name()}\")\n",
    "    case \"cpu\":\n",
    "        print(\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad98e33",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "`chopin-notes` is a custom dataset that I collected a year ago for a side project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a8daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4289\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/chopin-notes\", \"rb\") as f:\n",
    "    notes: list[str] = pickle.load(f)\n",
    "\n",
    "unique_notes = list(set(notes))\n",
    "vocab_size = len(unique_notes)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "note_to_idx = {note: i for i, note in enumerate(unique_notes)}\n",
    "idx_to_note = {i: note for note, i in note_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437dd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, B: int, L: int):\n",
    "        \"\"\"\n",
    "        Dataloader to parse data in a format needed to train Large Language models.\n",
    "        \"\"\"\n",
    "        self.B = B\n",
    "        self.L = L\n",
    "\n",
    "        ids = list(map(note_to_idx.get, notes))\n",
    "        ids = torch.Tensor(ids).type(torch.long)\n",
    "\n",
    "        self.tokens = ids\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, L = self.B, self.L\n",
    "        buf = self.tokens[self.current_position : self.current_position + B * L + 1]\n",
    "        inputs = (buf[:-1]).view(B, L)\n",
    "        targets = (buf[1:]).view(B, L)\n",
    "        self.current_position += B * L\n",
    "\n",
    "        if self.current_position + B * L < len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e2e55",
   "metadata": {},
   "source": [
    "# Set up and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce96a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/nick/anaconda3/envs/xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__', '-isystem', '/home/nick/anaconda3/envs/xlstm/targets/x86_64-linux/include']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/nick/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/nick/.cache/torch_extensions/py311_cu126/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Total Parameters: 6.88M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/nick/anaconda3/envs/xlstm/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "cfg = OmegaConf.load(\"xlstm_config.yaml\")\n",
    "cfg = from_dict(data_class=xLSTMLMModelConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "model = xLSTMLMModel(cfg)\n",
    "\n",
    "# Print the size of the model (a number of parameters it has) in millions\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {num_params / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de04231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:12<00:00, 23.21it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE: int = 32\n",
    "CONTEXT_WINDOW: int = 128\n",
    "\n",
    "dataloader = DataLoader(B=BATCH_SIZE, L=CONTEXT_WINDOW)\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.95), eps=1e-8, fused=True)\n",
    "scheduler = CosineAnnealingLR(optimizer=optimizer, eta_min=1e-4, T_max=1000)\n",
    "\n",
    "with open(\"training_logs.csv\", mode=\"w\", newline=\"\", encoding=\"utf8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Step\", \"Loss\", \"Norm\", \"LR\", \"dt (ms)\", \"Tokens/sec\"])\n",
    "\n",
    "for step in tqdm(range(0, 301)):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs, targets = dataloader.next_batch()\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "    loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    tokens_processed =  dataloader.B * dataloader.L\n",
    "    tokens_per_sec = tokens_processed / dt\n",
    "    with open(\"training_logs.csv\", mode=\"a\", newline=\"\", encoding=\"utf8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([step, f\"{loss.item():.6f}\", f\"{norm:.4f}\", f\"{scheduler.get_last_lr()[0]:.4e}\", f\"{dt * 1000:.2f}\", f\"{tokens_per_sec:.2f}\"])\n",
    "\n",
    "torch.save(model.state_dict(), f\"xlstm_cp_{step}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e697887",
   "metadata": {},
   "source": [
    "### Let's generate a song using the last `context_window` notes from the dataset\n",
    "(the last sequence is used, because the model doesn't know how it continues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, max_length: int = 32, prompt: list[str] = \"\"):\n",
    "    model.eval()\n",
    "    ids = list(map(note_to_idx.get, prompt))\n",
    "    ids = torch.Tensor(ids).type(torch.long).to(device).unsqueeze(0)\n",
    "\n",
    "    while ids.size(1) < max_length:\n",
    "        with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            logits = model(ids)[:, -1, :]\n",
    "        ids = torch.cat((ids, torch.multinomial(F.softmax(logits, dim=-1), 1)), dim=1)\n",
    "\n",
    "    return list(map(idx_to_note.get, ids[0, :max_length].tolist()))\n",
    "\n",
    "generated_song = generate_text(model=model, max_length=128, prompt=notes[-CONTEXT_WINDOW:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2964fdf",
   "metadata": {},
   "source": [
    "### Convert the generated notes (`str` objects) to the `.mid` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ee4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_MAPPING = {\n",
    "    'C': 0, 'C#': 1, 'D': 2, 'D#': 3, 'E': 4, 'F': 5,\n",
    "    'F#': 6, 'G': 7, 'G#': 8, 'A': 9, 'A#': 10, 'B': 11\n",
    "}\n",
    "\n",
    "def note_to_midi(note):\n",
    "    if note[-1].isdigit():\n",
    "        pitch, octave = note[:-1], int(note[-1])\n",
    "        return (octave + 1) * 12 + NOTE_MAPPING[pitch]\n",
    "    return None\n",
    "\n",
    "midi = MidiFile()\n",
    "track = MidiTrack()\n",
    "midi.tracks.append(track)\n",
    "tempo = 120  # BPM\n",
    "tick_duration = midi.ticks_per_beat // 4  # 16th note\n",
    "\n",
    "for note_group in generated_song:\n",
    "    note_list = note_group.split('.')\n",
    "    midi_numbers = [note_to_midi(note) for note in note_list if note_to_midi(note) is not None]\n",
    "    for midi_num in midi_numbers:\n",
    "        track.append(Message('note_on', note=midi_num, velocity=64, time=0))\n",
    "    for midi_num in midi_numbers:\n",
    "        track.append(Message('note_off', note=midi_num, velocity=64, time=tick_duration))\n",
    "\n",
    "midi_path = \"generated_song.mid\"\n",
    "midi.save(midi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae52e7",
   "metadata": {},
   "source": [
    "## The file was converted to `.mp3` and attached to this repo.\n",
    "\n",
    "# Listen to it -> `hw06/README.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
