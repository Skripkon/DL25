{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f271af84",
   "metadata": {},
   "source": [
    "# Hard VS Soft predict with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a744da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from typing import Literal\n",
    "import re\n",
    "\n",
    "import kagglehub  # pip install kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from together import Together\n",
    "\n",
    "from prompts import (\n",
    "    SYSTEM_PROMPT,\n",
    "    CLASSIFY_SOFT_PROMPT_TEMPLATE,\n",
    "    CLASSIFY_HARD_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654aaf2",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "[View on Kaggle](https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification)\n",
    "\n",
    "A **subset** of the original dataset was used for computational efficiency:\n",
    "\n",
    "- **4 classes**\n",
    "- **250 samples per class**\n",
    "- **1000 samples total**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf89ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  4\n",
      "Original: (50424, 2)\n",
      "Used: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Household</td>\n",
       "      <td>Generic Imported 30Pcs Assorted Hand Sewing Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Household</td>\n",
       "      <td>Vardhman Bunny Mix 4 no. (6 pc Pack) Wool Ball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Devil Boy's PU Leather Belt (Black) Devil is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Books</td>\n",
       "      <td>Society Tea Premium Darjeeling Tea, 250g Once ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Probiker Half Finger Motorcycle Riding Gloves ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label                                               text\n",
       "119               Household  Generic Imported 30Pcs Assorted Hand Sewing Ne...\n",
       "130               Household  Vardhman Bunny Mix 4 no. (6 pc Pack) Wool Ball...\n",
       "566  Clothing & Accessories  Devil Boy's PU Leather Belt (Black) Devil is t...\n",
       "302                   Books  Society Tea Premium Darjeeling Tea, 250g Once ...\n",
       "631  Clothing & Accessories  Probiker Half Finger Motorcycle Riding Gloves ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = kagglehub.dataset_download(\"saurabhshahane/ecommerce-text-classification\")\n",
    "csv_file = os.listdir(data_dir)[0]\n",
    "csv_path = os.path.join(data_dir, csv_file)\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv(csv_path) # type: ignore\n",
    "data = data.rename(columns={\n",
    "                       data.columns[0]: \"label\",\n",
    "                       data.columns[1]: \"text\"\n",
    "                    })\n",
    "\n",
    "classes: np.ndarray = data[\"label\"].unique()\n",
    "\n",
    "print(\"Labels: \", len(classes))\n",
    "print(f\"Original: {data.shape}\")\n",
    "\n",
    "# Keep only N examples of each category (N is a hyperparameter. Say, N=250)\n",
    "N = 250\n",
    "subset_data = pd.DataFrame()\n",
    "for label in classes:\n",
    "    label_data = data[data[\"label\"] == label].head(N)\n",
    "    subset_data = pd.concat([subset_data, label_data], ignore_index=True)\n",
    "\n",
    "data = subset_data.sample(frac=1)  # shuffle data\n",
    "print(f\"Used: {data.shape}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a629901",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16  # for parallel calls\n",
    "client = Together(api_key=os.getenv(\"TOGETHER_API_KEY\"))\n",
    "\n",
    "def classify_and_evaluate(mode: Literal[\"soft\", \"hard\"], model_name):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    # Choose prompt based on the mode\n",
    "    prompt = CLASSIFY_HARD_PROMPT_TEMPLATE if mode == \"hard\" else CLASSIFY_SOFT_PROMPT_TEMPLATE\n",
    "\n",
    "    # Prepare prompts\n",
    "    all_prompts = [\n",
    "        prompt.format(description=row[\"text\"])\n",
    "        for _, row in data.iterrows()\n",
    "    ]\n",
    "    all_labels = data[\"label\"].tolist()\n",
    "\n",
    "    def classify(prompt):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            content = response.choices[0].message.content.strip()  # type: ignore\n",
    "            \n",
    "            # Extract content between <answer> tags\n",
    "            answer_match = re.search(r\"<answer>(.*?)</answer>\", content, re.DOTALL)\n",
    "            if not answer_match:\n",
    "                raise ValueError(\"No answer tags found in response\")\n",
    "                \n",
    "            answer_content = answer_match.group(1).strip()\n",
    "            answer = ast.literal_eval(answer_content)\n",
    "\n",
    "            if mode == \"soft\":\n",
    "                return max(answer, key=answer.get)\n",
    "            \n",
    "            return answer[\"Category\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return \"ERROR 239\"\n",
    "\n",
    "    # Batch and parallelize\n",
    "    for i in tqdm(range(0, len(all_prompts), BATCH_SIZE), desc=\"Processing Batches\"):\n",
    "        batch_prompts = all_prompts[i:i + BATCH_SIZE]\n",
    "        batch_labels = all_labels[i:i + BATCH_SIZE]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:\n",
    "            batch_predictions = list(executor.map(classify, batch_prompts))\n",
    "\n",
    "        predictions.extend(batch_predictions)\n",
    "        targets.extend(batch_labels)\n",
    "\n",
    "    n_correct: int = 0\n",
    "\n",
    "    for p, t in zip(predictions, targets):\n",
    "        if p == t:\n",
    "            n_correct += 1\n",
    "    accuracy = n_correct / data.shape[0]\n",
    "    \n",
    "    print(f\"\"\"[{model_name.split(\"/\")[-1]}][{mode}] Accuracy: {n_correct / data.shape[0]}\"\"\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dc472",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dcaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 63/63 [01:33<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exaone-3-5-32b-instruct][hard] Accuracy: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 63/63 [02:12<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exaone-3-5-32b-instruct][soft] Accuracy: 0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "modes: list[Literal[\"hard\", \"soft\"]] = [\"hard\", \"soft\"]\n",
    "models = [\"lgai/exaone-3-5-32b-instruct\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for mode in modes:\n",
    "    for model in models:\n",
    "        accuracy = classify_and_evaluate(mode=mode, model_name=model)\n",
    "        results.append([mode, model, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce247fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------+\n",
      "| Mode   | Model                        |   Accuracy |\n",
      "+========+==============================+============+\n",
      "| hard   | lgai/exaone-3-5-32b-instruct |      0.854 |\n",
      "+--------+------------------------------+------------+\n",
      "| soft   | lgai/exaone-3-5-32b-instruct |      0.862 |\n",
      "+--------+------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(results, headers=[\"Mode\", \"Model\", \"Accuracy\"], floatfmt=\".3f\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb7061",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Soft prediction (label smoothing) showed slighly better performance (**+0.8%**) in comparison with the hard prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
