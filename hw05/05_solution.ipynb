{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework assignment №5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation (with Mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from mambapy.lm import MambaConfig\n",
    "from mambapy.lm import LM as MambaLM\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "match device.type:\n",
    "    case \"cuda\":\n",
    "        print(f\"Device: {torch.cuda.get_device_name()}\")\n",
    "    case \"cpu\":\n",
    "        print(\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "`chopin-notes` is a custom dataset that I collected a year ago for a side project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4289\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/chopin-notes\", \"rb\") as f:\n",
    "    notes: list[str] = pickle.load(f)\n",
    "\n",
    "unique_notes = list(set(notes))\n",
    "vocab_size = len(unique_notes)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "note_to_idx = {note: i for i, note in enumerate(unique_notes)}\n",
    "idx_to_note = {i: note for note, i in note_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, B: int, L: int):\n",
    "        \"\"\"\n",
    "        Dataloader to parse data in a format needed to train Large Language models.\n",
    "        \"\"\"\n",
    "        self.B = B\n",
    "        self.L = L\n",
    "\n",
    "        ids = list(map(note_to_idx.get, notes))\n",
    "        ids = torch.Tensor(ids).type(torch.long)\n",
    "\n",
    "        self.tokens = ids\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, L = self.B, self.L\n",
    "        buf = self.tokens[self.current_position : self.current_position + B * L + 1]\n",
    "        inputs = (buf[:-1]).view(B, L)\n",
    "        targets = (buf[1:]).view(B, L)\n",
    "        self.current_position += B * L\n",
    "\n",
    "        if self.current_position + B * L < len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:36<00:00,  8.30it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE: int = 32\n",
    "CONTEXT_WINDOW: int = 512\n",
    "\n",
    "dataloader = DataLoader(B=BATCH_SIZE, L=CONTEXT_WINDOW)\n",
    "config = MambaConfig(d_model=BATCH_SIZE, n_layers=4)\n",
    "model = MambaLM(config, vocab_size=vocab_size)\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.95), eps=1e-8, fused=True)\n",
    "scheduler = CosineAnnealingLR(optimizer=optimizer, eta_min=1e-4, T_max=1000)\n",
    "\n",
    "with open(\"training_logs.csv\", mode=\"w\", newline=\"\", encoding=\"utf8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Step\", \"Loss\", \"Norm\", \"LR\", \"dt (ms)\", \"Tokens/sec\"])\n",
    "\n",
    "for step in tqdm(range(0, 301)):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs, targets = dataloader.next_batch()\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "    loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    tokens_processed =  dataloader.B * dataloader.L\n",
    "    tokens_per_sec = tokens_processed / dt\n",
    "    with open(\"training_logs.csv\", mode=\"a\", newline=\"\", encoding=\"utf8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([step, f\"{loss.item():.6f}\", f\"{norm:.4f}\", f\"{scheduler.get_last_lr()[0]:.4e}\", f\"{dt * 1000:.2f}\", f\"{tokens_per_sec:.2f}\"])\n",
    "\n",
    "torch.save(model.state_dict(), f\"mamba_cp_{step}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate a song using the last `context_window` notes from the dataset\n",
    "(the last sequence is used, because the model doesn't know how it continues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, notes_to_generate: int = 32, prompt: list[str] = \"\"):\n",
    "    model.eval()\n",
    "    ids = list(map(note_to_idx.get, prompt))\n",
    "    ids = torch.Tensor(ids).type(torch.long).to(device).unsqueeze(0)\n",
    "    generated_tokens = []\n",
    "\n",
    "    for _ in range(notes_to_generate):\n",
    "        with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            logits = model(ids)[:, -1, :]\n",
    "        next_token = torch.multinomial(F.softmax(logits, dim=-1), 1)\n",
    "        generated_tokens.append(next_token.item())\n",
    "        prompt = torch.cat((ids[:, 1:], torch.multinomial(F.softmax(logits, dim=-1), 1)), dim=1)\n",
    "\n",
    "    return list(map(idx_to_note.get, generated_tokens))\n",
    "\n",
    "generated_song = generate_text(model=model, notes_to_generate=512, prompt=notes[-CONTEXT_WINDOW:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the generated notes (`str` objects) to the `.mid` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_MAPPING = {\n",
    "    'C': 0, 'C#': 1, 'D': 2, 'D#': 3, 'E': 4, 'F': 5,\n",
    "    'F#': 6, 'G': 7, 'G#': 8, 'A': 9, 'A#': 10, 'B': 11\n",
    "}\n",
    "\n",
    "def note_to_midi(note):\n",
    "    if note[-1].isdigit():\n",
    "        pitch, octave = note[:-1], int(note[-1])\n",
    "        return (octave + 1) * 12 + NOTE_MAPPING[pitch]\n",
    "    return None\n",
    "\n",
    "midi = MidiFile()\n",
    "track = MidiTrack()\n",
    "midi.tracks.append(track)\n",
    "tempo = 120  # BPM\n",
    "tick_duration = midi.ticks_per_beat // 4  # 16th note\n",
    "\n",
    "for note_group in generated_song:\n",
    "    note_list = note_group.split('.')\n",
    "    midi_numbers = [note_to_midi(note) for note in note_list if note_to_midi(note) is not None]\n",
    "    for midi_num in midi_numbers:\n",
    "        track.append(Message('note_on', note=midi_num, velocity=64, time=0))\n",
    "    for midi_num in midi_numbers:\n",
    "        track.append(Message('note_off', note=midi_num, velocity=64, time=tick_duration))\n",
    "\n",
    "midi_path = \"generated_song.mid\"\n",
    "midi.save(midi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The file was converted to `.mp3` and attached to this repo.\n",
    "\n",
    "# Listen to it -> `hw05/README.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
